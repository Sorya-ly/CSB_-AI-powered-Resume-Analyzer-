{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dad66b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"contact\": {\n",
      "        \"email\": [\n",
      "            \"johndoe@gmail.com\"\n",
      "        ],\n",
      "        \"phone\": [\n",
      "            \"+1 234 567 8901\"\n",
      "        ]\n",
      "    },\n",
      "    \"skills\": [\n",
      "        \"Django\",\n",
      "        \"HTML\",\n",
      "        \"Python\",\n",
      "        \"AWS\",\n",
      "        \"Docker\",\n",
      "        \"CSS\"\n",
      "    ],\n",
      "    \"education\": [\n",
      "        {\n",
      "            \"institution\": \"ABC University\",\n",
      "            \"degree\": \"Bachelor\"\n",
      "        }\n",
      "    ],\n",
      "    \"experience\": [\n",
      "        {\n",
      "            \"company\": \"ABC University\",\n",
      "            \"role\": \"+1 234 567 8901\\n    Education: Bachelor of Science in Computer Science, ABC University (2020)\\n    Experience:\\n    - Software Engineer at XYZ Company, built web apps with Python and Django\\n    - Worked with Docker and AWS for deployment\\n    Skills: Python, Django, Docker, AWS, HTML, CSS\"\n",
      "        }\n",
      "    ],\n",
      "    \"job_matches\": [\n",
      "        {\n",
      "            \"title\": \"Web Developer\",\n",
      "            \"score\": 2\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"DevOps Engineer\",\n",
      "            \"score\": 2\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Data Scientist\",\n",
      "            \"score\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "\n",
    "# ---------- Load Models and Data ----------\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load predefined skill-to-job mapping\n",
    "with open(\"job_skill_map.json\", \"r\") as f:\n",
    "    JOB_SKILL_MAP = json.load(f)\n",
    "\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "def extract_emails(text):\n",
    "    return re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    return re.findall(r'\\+?\\d[\\d\\s-]{8,}\\d', text)\n",
    "\n",
    "\n",
    "def extract_dates(text):\n",
    "    return re.findall(r'\\b(?:19|20)\\d{2}\\b', text)  # matches years like 2020, 2019\n",
    "\n",
    "\n",
    "# ---------- Skill Extraction ----------\n",
    "def load_skill_list():\n",
    "    \"\"\"A sample hardcoded list — you can expand it from datasets later.\"\"\"\n",
    "    return [\n",
    "        \"Python\", \"Java\", \"C++\", \"JavaScript\", \"React\", \"Node.js\", \"HTML\", \"CSS\",\n",
    "        \"SQL\", \"Django\", \"Flask\", \"TensorFlow\", \"Keras\", \"Docker\", \"Kubernetes\",\n",
    "        \"AWS\", \"Git\", \"Linux\", \"Pandas\", \"NumPy\", \"Machine Learning\", \"Deep Learning\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def extract_skills(text):\n",
    "    \"\"\"Use spaCy PhraseMatcher for flexible skill detection.\"\"\"\n",
    "    skills = load_skill_list()\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "    patterns = [nlp.make_doc(skill) for skill in skills]\n",
    "    matcher.add(\"SKILLS\", patterns)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    found = list({doc[start:end].text for _, start, end in matches})\n",
    "    return found\n",
    "\n",
    "\n",
    "# ---------- Education Extraction ----------\n",
    "def extract_education(text):\n",
    "    \"\"\"Find degree names and institutions using regex + spaCy NER.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    education_entries = []\n",
    "\n",
    "    # Find education-related orgs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\" and re.search(r\"University|College|Institute|School\", ent.text, re.I):\n",
    "            education_entries.append({\"institution\": ent.text})\n",
    "\n",
    "    # Find degrees\n",
    "    degrees = re.findall(r'(Bachelor|Master|PhD|BSc|MSc|BA|MA)[^,\\n]*', text, re.I)\n",
    "    for deg in degrees:\n",
    "        if not education_entries:\n",
    "            education_entries.append({\"degree\": deg})\n",
    "        else:\n",
    "            education_entries[0][\"degree\"] = deg\n",
    "\n",
    "    return education_entries\n",
    "\n",
    "\n",
    "# ---------- Experience Extraction ----------\n",
    "def extract_experience(text):\n",
    "    \"\"\"Basic experience extraction by finding company/org and job title patterns.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    experiences = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        if re.search(r'\\b(Engineer|Developer|Manager|Analyst|Designer)\\b', sent.text, re.I):\n",
    "            company = None\n",
    "            for ent in sent.ents:\n",
    "                if ent.label_ == \"ORG\":\n",
    "                    company = ent.text\n",
    "                    break\n",
    "            experiences.append({\n",
    "                \"company\": company or \"Unknown\",\n",
    "                \"role\": sent.text.strip()\n",
    "            })\n",
    "\n",
    "    return experiences\n",
    "\n",
    "\n",
    "# ---------- Skill-to-Job Matching ----------\n",
    "def match_jobs(found_skills):\n",
    "    \"\"\"Compare extracted skills to job categories in JOB_SKILL_MAP.\"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    for job, job_skills in JOB_SKILL_MAP.items():\n",
    "        overlap = set(found_skills) & set(job_skills)\n",
    "        scores[job] = len(overlap)\n",
    "\n",
    "    # Sort jobs by most matches\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_matches = [{\"title\": job, \"score\": score} for job, score in ranked if score > 0]\n",
    "    return top_matches[:3]  # Return top 3 suggestions\n",
    "\n",
    "\n",
    "# ---------- Main Function ----------\n",
    "def analyze_resume(text):\n",
    "    \"\"\"Main function: extract structured data and match job categories.\"\"\"\n",
    "    result = {\n",
    "        \"contact\": {\n",
    "            \"email\": extract_emails(text),\n",
    "            \"phone\": extract_phone_numbers(text)\n",
    "        },\n",
    "        \"skills\": extract_skills(text),\n",
    "        \"education\": extract_education(text),\n",
    "        \"experience\": extract_experience(text)\n",
    "    }\n",
    "\n",
    "    # Match jobs\n",
    "    result[\"job_matches\"] = match_jobs(result[\"skills\"])\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------- Example Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\n",
    "    John Doe\n",
    "    Email: johndoe@gmail.com | Phone: +1 234 567 8901\n",
    "    Education: Bachelor of Science in Computer Science, ABC University (2020)\n",
    "    Experience:\n",
    "    - Software Engineer at XYZ Company, built web apps with Python and Django\n",
    "    - Worked with Docker and AWS for deployment\n",
    "    Skills: Python, Django, Docker, AWS, HTML, CSS\n",
    "    \"\"\"\n",
    "\n",
    "    structured = analyze_resume(sample_text)\n",
    "    print(json.dumps(structured, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6876a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp313-cp313-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.4.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp313-cp313-macosx_11_0_arm64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp313-cp313-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.10-cp313-cp313-macosx_11_0_arm64.whl (124 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp313-cp313-macosx_11_0_arm64.whl (632 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.8/632.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.6-cp313-cp313-macosx_11_0_arm64.whl (832 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.7/832.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp313-cp313-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.2-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.4.4-py3-none-any.whl (63 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.3.1-cp313-cp313-macosx_11_0_arm64.whl (154 kB)\n",
      "Installing collected packages: cymem, wasabi, typer-slim, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [spacy]m18/19\u001b[0m [spacy]ge-data]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 murmurhash-1.0.13 preshed-3.0.10 smart-open-7.4.4 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-slim-0.20.0 wasabi-1.1.3 weasel-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
